## Test and develop functions to adapt p-values and alpha levels as the tree grows

## The next lines are for use when creating the tests. We want interactive<-FALSE for production
interactive <- FALSE
if (interactive) {
  library(devtools)
  library(testthat)
  local_edition(3)
  library(here)
  library(data.table)
  library(dtplyr)
  # remotes::install_github("bowers-illinois-edu/TreeTestSim")
  # library(TreeTestSim)
  # load_all("~/repos/TreeTestSim")
  ## This next creates and loads different datasets that we use
  source(here("tests/testthat", "make_test_data.R"))
  ## This next is a copy from the package TreeTestSim
  ## source(here("tests/testthat", "generate_tree.R"))
  load_all() ## use  this during debugging
}
setDTthreads(1)
options(digits = 4)

test_that("find_blocks should give reasonable answers in the true null situation", {
  ## First just see if find_blocks itself operates with no local
  ## adjustment or alpha adjustment and fixed block structure. bdt1
  ## and idt come from generate_tree(k=4,l=3) and Y=y0 in that case

  expect_equal(unique(idt[, Y - y0]), 0)
  set.seed(12345)
  res_null <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = NULL, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )
  # We expect a single test with a p>.05 (this depends on the set.seed above, but mostly should be true)
  expect_equal(length(unique(res_null$bdat$pfinalb)), 1)
  expect_gt(unique(res_null$bdat$pfinalb), .05)
  expect_gt(res_null$node_dat$p, .05)
  expect_equal(nrow(res_null$node_dat), 1)
})


test_that("Unadjusted block finding produces sensible results", {
  ## First with no adjustment
  set.seed(12345)
  res_half <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = NULL, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  res_half$node_dat

  ## Just a note on the different approaches to summarizing the results. the
  ## make_results_tree tries to produce a row for every block but the node level
  ## results from find_blocks does not (at least for now)

  res_half_tree <- make_results_tree(res_half, block_id = "bF")
  res_half_tree$nodes %>%
    select(-blocks) %>%
    arrange(depth, parent_name)
  ## The number of not missing p-values should be the same
  expect_equal(sum(!is.na(res_half_tree$nodes$p)), sum(!is.na(res_half$node_dat$p)))

  ## Just checking that they make the same p-values for the nodes with hashed
  ## nodenames (nodenames generated by find_blocks for nodes that were actually
  ## tested.)

  test_node_representations <- left_join(res_half_tree$nodes, res_half$node_dat, by = join_by(name == nodenum))
  expect_equal(test_node_representations$p.x, test_node_representations$p.y)
})


test_that("The local adjustment approaches produce sensible results", {
  ## Now try with some of the local and other adjustments.

  set.seed(12345)
  res_half <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = NULL, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  set.seed(12345)
  res_half_simes <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = local_simes, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  set.seed(12345)
  res_half_hommel <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = local_hommel_all_ps, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  res_half_minp <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = local_min_p, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  res_half_bh <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = local_bh_all_ps, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  ## This next is not necessary but it was useful to have a non-null function for
  ## some other simulations
  res_half_unadj <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL,
    local_adj_p_fn = local_unadj_all_ps, simthresh = 20, sims = 1000, maxtest = 2000,
    thealpha = .05, thew0 = 0.05 - 0.001,
    fmla = Y_half_tau1 ~ trtF | bF, splitby = "lvls_fac",
    blocksize = "nb", trace = TRUE, copydts = TRUE, stop_splitby_constant = TRUE,
    return_what = c("blocks", "nodes")
  )

  setkey(res_half$bdat, "bF")
  setkey(res_half_hommel$bdat, "bF")
  setkey(res_half_unadj$bdat, "bF")
  setkey(res_half_simes$bdat, "bF")
  setkey(res_half_bh$bdat, "bF")
  setkey(res_half_minp$bdat, "bF")

  ## This just checkes that the local_unadj_all_ps does what it should --- make no adjustment.
  expect_equal(res_half$bdat$pfinalb, res_half_unadj$bdat$pfinalb)
  expect_equal(res_half$node_dat$p, res_half_unadj$node_dat$p)

  res_half_tree <- make_results_tree(res_half, block_id = "bF", return_what = "nodes")$nodes
  res_half_hommel_tree <- make_results_tree(res_half_hommel, block_id = "bF", return_what = "nodes")$nodes
  res_half_bh_tree <- make_results_tree(res_half_bh, block_id = "bF", return_what = "nodes")$nodes
  res_half_simes_tree <- make_results_tree(res_half_simes, block_id = "bF", return_what = "nodes")$nodes
  res_half_minp_tree <- make_results_tree(res_half_minp, block_id = "bF", return_what = "nodes")$nodes

  setkey(res_half_tree, depth, node_number)
  setkey(res_half_hommel_tree, depth, node_number)
  setkey(res_half_simes_tree, depth, node_number)
  setkey(res_half_bh_tree, depth, node_number)
  setkey(res_half_minp_tree, depth, node_number)

  head(res_half_tree) %>% select(-blocks)
  head(res_half_hommel_tree) %>% select(-blocks)

  # Different adjustment methods may create different tree structures
  # Test basic properties instead of exact node-by-node equality

  # All methods should create valid tree structures with at least a root node
  expect_true(nrow(res_half_tree) > 0)
  expect_true(nrow(res_half_hommel_tree) > 0)
  expect_true(nrow(res_half_simes_tree) > 0)
  expect_true(nrow(res_half_bh_tree) > 0)
  expect_true(nrow(res_half_minp_tree) > 0)

  # All should have a root node at depth 1
  expect_true(1 %in% res_half_tree$depth)
  expect_true(1 %in% res_half_hommel_tree$depth)
  expect_true(1 %in% res_half_simes_tree$depth)
  expect_true(1 %in% res_half_bh_tree$depth)
  expect_true(1 %in% res_half_minp_tree$depth)

  # Node numbers should be positive integers
  expect_true(all(res_half_tree$node_number > 0))
  expect_true(all(res_half_hommel_tree$node_number > 0))
  expect_true(all(res_half_simes_tree$node_number > 0))
  expect_true(all(res_half_bh_tree$node_number > 0))
  expect_true(all(res_half_minp_tree$node_number > 0))

  ## Check the differences between the p-values for nodes that exist in multiple methods
  # Use full outer join to get all nodes from all methods
  tmp0 <- merge(res_half_tree, res_half_hommel_tree, by = "name", all = TRUE, suffixes = c("_unadj", "_hommel"))
  tmp1 <- merge(tmp0, res_half_simes_tree[, .(name, p)], by = "name", all = TRUE, suffixes = c("", "_simes"))
  setnames(tmp1, "p", "p_simes")
  tmp2 <- merge(tmp1, res_half_minp_tree[, .(name, p)], by = "name", all = TRUE, suffixes = c("", "_minp"))
  setnames(tmp2, "p", "p_minp")
  test_local_adj_ps <- merge(tmp2, res_half_bh_tree[, .(name, p)], by = "name", all = TRUE, suffixes = c("", "_bh"))
  setnames(test_local_adj_ps, "p", "p_bh")

  # The merged data should have at least as many rows as any individual tree
  expect_true(nrow(test_local_adj_ps) >= nrow(res_half_tree))
  expect_true(nrow(test_local_adj_ps) >= nrow(res_half_hommel_tree))
  expect_true(nrow(test_local_adj_ps) >= nrow(res_half_simes_tree))
  expect_true(nrow(test_local_adj_ps) >= nrow(res_half_bh_tree))
  expect_true(nrow(test_local_adj_ps) >= nrow(res_half_minp_tree))

  test_local_adj_ps %>% select(name, starts_with("p_"))

  ## We expect that the p-values for hommel and bh should be higher than the unadjusted p-values at the same nodes
  # Only test where both p-values are available
  valid_hommel <- !is.na(test_local_adj_ps$p_unadj) & !is.na(test_local_adj_ps$p_hommel)
  valid_bh <- !is.na(test_local_adj_ps$p_unadj) & !is.na(test_local_adj_ps$p_bh)

  if (sum(valid_hommel) > 0) {
    expect_true(all(test_local_adj_ps[valid_hommel, p_unadj <= p_hommel]))
  }
  if (sum(valid_bh) > 0) {
    expect_true(all(test_local_adj_ps[valid_bh, p_unadj <= p_bh]))
  }

  ## The next two are more ad hoc and so we are not sure what to expect all the time.
  test_local_adj_ps[, range(p_unadj - p_simes, na.rm = TRUE)]
  test_local_adj_ps[, range(p_unadj - p_minp, na.rm = TRUE)]

  # with(test_local_adj_ps,plot(p_unadj,p_minp))
  # abline(0,1)

  ## Not clear expectations for how deep into the tree we should expect the local
  ## adjustments to allow.
  ## Looks like some of them go all the way and others stop
  ## like the unadjusted.

  c(
    sum(!is.na(res_half_tree$p)),
    sum(!is.na(res_half_bh_tree$p)),
    sum(!is.na(res_half_minp_tree$p)),
    sum(!is.na(res_half_simes_tree$p)),
    sum(!is.na(res_half_hommel_tree$p))
  )
})

test_that("intuitions work about the adjustments when it comes to false positive rates.", {
  skip_on_ci()
  skip_on_cran()
  skip() ## debugging make check
  nsims <- 1000
  sim_err <- 2 * sqrt((.05 * (1 - .05)) / nsims)
  ncores_machine <- max(c(1, parallel::detectCores() - 2))
  ## First, in completely null situation.
  set.seed(12345)
  p_null_res <- padj_test_fn(
    idat = idt,
    bdat = bdt1,
    blockid = "bF",
    trtid = "trt", ## needs to be a 0 or a 1 for the simulation
    fmla = Y ~ trtF | bF,
    ybase = "y0",
    prop_blocks_0 = 1,
    tau_fn = tau_null,
    tau_size = 0,
    covariate = NULL,
    pfn = pOneway,
    nsims = nsims,
    ncores = 1,
    ncores_sim = ncores_machine,
    afn = NULL,
    splitfn = splitSpecifiedFactorMulti,
    splitby = "lvls_fac",
    p_adj_method = "split",
    blocksize = "nb",
    by_block = TRUE,
    stop_splitby_constant = TRUE,
    local_adj_p_fn = local_unadj_all_ps,
    bottom_up_adj = "hommel",
  )

  res_null_rates <- p_null_res[, lapply(.SD, mean, na.rm = TRUE)]
  t(res_null_rates)

  ## This is assessing weak control so the following two are equal.
  expect_lt(res_null_rates$node_false_rejection_prop, .05 + sim_err)
  expect_lt(res_null_rates$bot_leaf_false_rejection_prop, .05 + sim_err)

  ## For all p-value functions
  p_val_funs <- c("pWilcox", "pIndepDist", "pTestTwice", "pCombCauchyDist")

  null_ps <- sapply(p_val_funs, function(pfnnm) {
    message(pfnnm)
    set.seed(12345)
    p_null_res <- padj_test_fn(
      idat = idt,
      bdat = bdt1,
      blockid = "bF",
      trtid = "trt", ## needs to be a 0 or a 1 for the simulation
      fmla = Y ~ trtF | bF,
      ybase = "y0",
      prop_blocks_0 = 1,
      tau_fn = tau_null,
      tau_size = 0,
      covariate = NULL,
      pfn = getFromNamespace(pfnnm, ns = "manytestsr"),
      nsims = nsims,
      ncores = 1,
      ncores_sim = ncores_machine,
      afn = NULL,
      splitfn = splitSpecifiedFactorMulti,
      splitby = "lvls_fac",
      p_adj_method = "split",
      blocksize = "nb",
      by_block = TRUE,
      stop_splitby_constant = TRUE,
      local_adj_p_fn = local_unadj_all_ps,
      bottom_up_adj = "hommel",
    )

    res_null_rates <- p_null_res[, lapply(.SD, mean, na.rm = TRUE)]
    return(t(res_null_rates))
  })

  null_ps_dt <- as.data.frame(null_ps)
  null_ps_dt$stat <- names(res_null_rates)
  fwer_measures <- null_ps_dt %>%
    filter(stat %in% c("node_false_rejection_prop", "leaf_false_rejection_prop", "bot_leaf_false_rejection_prop"))

  expect_true(all(fwer_measures[, p_val_funs] < .05 + sim_err))
})


test_that("We have strong control of the FWER in some cases", {
  ## The tau_size and prop_blocks_0 and block size below should produce very high
  ## power for each block a 1 sd difference
  # power.t.test(power=.8,sd=1,delta=1,sig.level=.05)
  skip_on_ci()
  skip_on_cran()
  skip()

  nsims <- 1000
  sim_err <- 2 * sqrt((.05 * (1 - .05)) / nsims)
  ncores_machine <- max(c(1, parallel::detectCores() - 2))
  power.t.test(n = 25, sd = 1, delta = 1, sig.level = .05)
  unique(table(idt$bF))
  ## For all p-value functions
  p_val_funs <- c("pOneway", "pWilcox", "pIndepDist", "pTestTwice", "pCombCauchyDist")

  half_res <- lapply(p_val_funs, function(pfnnm) {
    message(pfnnm)
    set.seed(12345)
    res <- padj_test_fn(
      idat = idt,
      bdat = bdt1,
      blockid = "bF",
      trtid = "trt", ## needs to be a 0 or a 1 for the simulation
      fmla = Y ~ trtF | bF,
      ybase = "y0",
      prop_blocks_0 = .5,
      tau_fn = tau_norm,
      tau_size = 1,
      covariate = NULL,
      pfn = getFromNamespace(pfnnm, ns = "manytestsr"),
      nsims = nsims,
      ncores = 1,
      ncores_sim = ncores_machine,
      afn = NULL,
      splitfn = splitSpecifiedFactorMulti,
      splitby = "lvls_fac",
      p_adj_method = "split",
      blocksize = "nb",
      by_block = TRUE,
      stop_splitby_constant = TRUE,
      local_adj_p_fn = local_unadj_all_ps,
      bottom_up_adj = "hommel",
    )
    res_rates <- res[, lapply(.SD, mean, na.rm = TRUE)]
    return(t(res_rates))
  })

  names(half_res) <- p_val_funs
  half_res_dt <- as.data.frame(half_res)
  half_res_dt$stat <- row.names(half_res_dt)

  test_measures <- half_res_dt %>%
    filter(stat %in% c(
      "node_false_rejection_prop",
      "leaf_false_rejection_prop", "bot_leaf_false_rejection_prop",
      "node_power", "leaf_power", "bot_leaf_power"
    ))

  fwer_meas <- test_measures %>%
    dplyr::filter(grepl("prop", stat)) %>%
    select(one_of(p_val_funs)) %>%
    unlist()

  expect_true(all(fwer_meas <= (.05 + sim_err)))

  power_meas <- test_measures %>%
    filter(stat %in% c("leaf_power", "node_power")) %>%
    select(one_of(p_val_funs)) %>%
    unlist()

  expect_true(all(power_meas > .05))

  ## these next lines are just to catch errors in running the code
  set.seed(12345)
  p_half_res <- padj_test_fn(
    idat = idt,
    bdat = bdt1,
    blockid = "bF",
    trtid = "trt", ## needs to be a 0 or a 1 for the simulation
    fmla = Y ~ trtF | bF,
    ybase = "y0",
    prop_blocks_0 = .5,
    tau_fn = tau_norm,
    tau_size = 1,
    covariate = NULL,
    pfn = pOneway,
    nsims = 10,
    ncores = 1,
    ncores_sim = 8,
    afn = NULL,
    splitfn = splitSpecifiedFactorMulti,
    splitby = "lvls_fac",
    p_adj_method = "split",
    blocksize = "nb",
    by_block = TRUE,
    stop_splitby_constant = TRUE,
    local_adj_p_fn = local_hommel_all_ps,
    bottom_up_adj = "hommel",
  )

  res_half_rates <- p_half_res[, lapply(.SD, mean, na.rm = TRUE)]
  t(res_half_rates)

  ## This is showing control of FWER in the strong sense.
  expect_lt(res_half_rates$node_false_rejection_prop, .05 + sim_err)
  ## Power to detect effects at the individual block level.
  res_half_rates$leaf_power
  ## This is a basic requirement of a good test: power above alpha
  expect_gt(res_half_rates$node_power, .05)
  res_half <- find_blocks(
    idat = idt, bdat = bdt1, blockid = "bF",
    splitfn = splitSpecifiedFactorMulti, pfn = pOneway, alphafn = NULL, local_adj_p_fn = NULL,
    fmla = Y_half_tau1 ~ trtF | bF,
    splitby = "lvls_fac", blocksize = "nb", trace = TRUE, copydts = TRUE
  )

  res_half

  res_half$bdat %>%
    select(node, level, parent, nonnull, lvls_fac, node_id, starts_with("g"), starts_with("p")) %>%
    mutate(across(where(is.numeric), zapsmall))

  res_half_tree <- make_results_tree(res_half, block_id = "bF", return_what = "all")
  res_half_graph <- make_results_ggraph(res_half_tree$graph)
  res_half_graph

  ## Now substitute the make_results_tree for calc_errs since we can now have
  ## error rates and power for both blocks ("leaves") and also non-leaf nodes
  ## (where we may make an error or not for a hypothesis referring to multiple
  ## leaves). Currently this is still slow but keeping it slow for clarity.
  ## TODO make this change in padj_test_fn...
  res_half_errs <- make_results_tree(res_half, block_id = "bF", return_what = "test_summary")
  res_half_errs
})

## Shuffle order  of the blocks so that the first set and the second set don't  automatically go together
set.seed(12345)
bdat4 <- bdat3[sample(.N), ]
## Setting up  a test of pre-specified splits
bdat4[, lv1 := cut(v1, 2, labels = c("l1_1", "l1_2"))]
bdat4[, lv2 := cut(v2, 2, labels = c("l2_1", "l2_2")), by = lv1]
bdat4[, lv3 := seq(1, .N), by = interaction(lv1, lv2, lex.order = TRUE, drop = TRUE)]
bdat4[, lvs := interaction(lv1, lv2, lv3, lex.order = TRUE, drop = TRUE)]

#### BELOW USES OLD CODE FOR DETECTING EFFECTS.
#### TODO: EITHER REIMPLEMENT USING current make_results_tree etc.. or delete

local_adj_methods <- c(
  "local_hommel_all_ps", "local_bh_all_ps",
  "local_simes", "local_unadj_all_ps"
)

alpha_and_splits <- expand.grid(
  afn = c("alpha_investing", "alpha_saffron", "alpha_addis", "NULL"),
  sfn = c(
    "splitCluster", "splitEqualApprox", "splitLOO",
    "splitSpecifiedFactor", "splitSpecifiedFactorMulti"
  ),
  local_adj_fn = local_adj_methods,
  stringsAsFactors = FALSE
)
alpha_and_splits$splitby <- "hwt"
alpha_and_splits$splitby[grep("Specified", alpha_and_splits$sfn)] <- "lvs"

testing_fn <- function(afn, sfn, local_adj, sby, fmla = Ytauv2 ~ ZF | bF, idat = idat3, bdat = bdat4) {
  if (afn == "NULL") {
    theafn <- NULL
  } else {
    theafn <- getFromNamespace(afn, ns = "manytestsr")
  }

  if (local_adj == "NULL") {
    local_adj <- NULL
  } else {
    local_adj <- getFromNamespace(local_adj, ns = "manytestsr")
  }
  ## afn and sfn and sby are character names
  theres <- find_blocks(
    idat = idat, bdat = bdat, blockid = "bF", splitfn = get(sfn),
    pfn = pTestTwice, alphafn = theafn, local_adj_p_fn = local_adj, thealpha = 0.05, thew0 = .05 - .001,
    fmla = fmla, simthresh = 1,
    copydts = TRUE, splitby = sby, stop_splitby_constant = TRUE, parallel = "multicore", ncores = 2
  )
  setkey(theres$bdat, bF)
  return(theres$bdat)[order(node_id)]
}

alpha_and_splits[c(1, 2, 4), ]
## debug(find_blocks)
res_ai <- testing_fn(
  afn = alpha_and_splits[1, "afn"],
  sfn = alpha_and_splits[1, "sfn"],
  local_adj = alpha_and_splits[1, "local_adj_fn"],
  sby = alpha_and_splits[1, "splitby"],
  idat = idat3, bdat = bdat4
)
res_saffron <- testing_fn(
  afn = alpha_and_splits[2, "afn"],
  sfn = alpha_and_splits[2, "sfn"],
  sby = alpha_and_splits[2, "splitby"],
  local_adj = alpha_and_splits[2, "local_adj_fn"],
  idat = idat3, bdat = bdat4
)
res_fwer <- testing_fn(
  afn = alpha_and_splits[4, "afn"],
  sfn = alpha_and_splits[4, "sfn"],
  sby = alpha_and_splits[4, "splitby"],
  local_adj = alpha_and_splits[4, "local_adj_fn"],
  idat = idat3, bdat = bdat4
)

grep("^p[0-9]", names(res_ai), value = TRUE)
grep("^p[0-9]", names(res_saffron), value = TRUE)
grep("^p[0-9]", names(res_fwer), value = TRUE)
options(digits = 3, scipen = 8)
res_ai[order(p1, p2, p3, p4, p5, p6, decreasing = TRUE), .(p1, p2, p3, p4, p5, p6)]
res_saffron[order(p1, p2, p3, p4, p5, p6, decreasing = TRUE), .(p1, p2, p3, p4, p5, p6)]
res_fwer[order(p1, p2, p3, p4, p5, p6, decreasing = TRUE), .(p1, p2, p3, p4, p5, p6)]
## Early in the splitting. No change
all.equal(res_ai$p2, res_saffron$p2)
all.equal(res_ai$p2, res_fwer$p2)
## But then some blocks stop testing
all.equal(res_ai$p5, res_saffron$p5)
all.equal(res_ai$p5, res_fwer$p5)
cbind(
  res_ai[, .(bF, p5, p6)],
  res_saffron[, .(bF, p5, p6)],
  res_fwer[, .(bF, p5, p6)]
)

## ## Which blocks were identified?
## ##
## ## The alpha investing style procedures should identify **more** blocks
## # We detect an effect in an individual block if:
## ## (1) the block is a leaf and that leaf has p < alpha
## # We detect an effect for a group of blocks if
## ## (2) the blocks are leaves with p > alpha but the parent of those blocks have p < alpha
##
## ## Change one result from res_fwer to enable us to check this:
##
## res_ai[bF %in% c("10", "9"), .(bF, ate_tauv2, pfinalb, nodenum_current, nodenum_prev, nodesize, p4, p5)]
## res_saffron[bF %in% c("10", "9"), .(bF, ate_tauv2, pfinalb, nodenum_current, nodenum_prev, nodesize, p4, p5)]
## res_fwer[bF %in% c("10", "9"), .(bF, ate_tauv2, pfinalb, nodenum_current, nodenum_prev, nodesize, p4, p5)]
##
## res_ai[bF == "10", p5 := .5]
## res_ai[bF == "10", pfinalb := .5]
## res_saffron[bF == "10", p5 := .5]
## res_saffron[bF == "10", pfinalb := .5]
## res_fwer[bF == "10", p5 := .5]
## res_fwer[bF == "10", pfinalb := .5]
##
## res_ai[bF %in% c("10", "9"), .(bF, ate_tauv2, pfinalb, nodenum_current, nodenum_prev, nodesize, p4, p5)]
## res_saffron[bF %in% c("10", "9"), .(bF, ate_tauv2, pfinalb, nodenum_current, nodenum_prev, nodesize, p4, p5)]
## res_fwer[bF %in% c("10", "9"), .(bF, ate_tauv2, pfinalb, nodenum_current, nodenum_prev, nodesize, p4, p5)]
##
## ## With alpha fixed
## res_fwer_det <- report_detections(res_fwer)
## ## So we can say that we discovered hits in the following blocks or groups of blocks
## res_fwer_det[(hit), .(node_id, bF, hit_grp, max_p, fin_parent_p, max_alpha, parent_alpha, single_hit, group_hit)][order(hit_grp)]
##
## ## With alpha varying according to the alpha investing
## res_ai_det <- report_detections(res_ai, fwer = FALSE)
## ## So we can say that we discovered hits in the following blocks or groups of blocks
## res_ai_det[(hit), .(node_id, bF, hit_grp, max_p, fin_parent_p, max_alpha, parent_alpha, single_hit, group_hit)][order(hit_grp)]
##
## ## And with the saffron procedure
## res_saffron_det <- report_detections(res_saffron, fwer = FALSE)
## ## So we can say that we discovered hits in the following blocks or groups of blocks
## res_saffron_det[(hit), .(node_id, bF, hit_grp, max_p, fin_parent_p, max_alpha, parent_alpha, single_hit, group_hit)][order(hit_grp)]
##
## res_fwer_tree <- make_results_tree(res_fwer, blockid = "bF")
## res_saffron_tree <- make_results_tree(res_saffron, blockid = "bF")
## res_ai_tree <- make_results_tree(res_ai, blockid = "bF")
##
## blahN <- res_fwer_tree %>%
##   activate(nodes) %>%
##   as_tibble()
## blahE <- res_fwer_tree %>%
##   activate(edges) %>%
##   as_tibble()
##
## res_fwer_g <- make_results_ggraph(res_fwer_tree)
## res_ai_g <- make_results_ggraph(res_ai_tree)
## res_saffron_g <- make_results_ggraph(res_saffron_tree)
##
## ## Compare these graphs to the results in res_ai_det and res_fwer_det above.
## ggsave(res_fwer_g, file = "res_fwer_g.pdf", bg = "transparent", width = 12, height = 10)
## ggsave(res_ai_g, file = "res_ai_g.pdf", bg = "transparent", width = 13, height = 10)
## ggsave(res_saffron_g, file = "res_saffron_g.pdf", bg = "transparent", width = 13, height = 10)
##
## ## Compare working with tree/graph versus blocks
## ## TODO. Does report_detections produce the same discoveries as make_results_tree?
##
## ## Criteria for comparisons:
## ## These functions can be used to run the tests for the different scenarios.
## ## They have hard coded the relationships in alpha_and_splits above for now.
##
## eval_numgrps <- function(detection_obj) {
##   numgrps <- sapply(detection_obj, function(dat) {
##     length(unique(dat$hit_grp))
##   })
##   ## names_split <- stri_split_regex(names(numgrps), "_", simplify = TRUE)
##
##   expect_lte(numgrps[[4]], max(numgrps[1:3])) ## FWER should be smaller than at least one of the alpha adjusters
##   expect_lte(numgrps[[8]], max(numgrps[5:7]))
##   expect_lte(numgrps[[12]], max(numgrps[9:11]))
##   expect_lte(numgrps[[16]], max(numgrps[13:15]))
##   expect_lte(numgrps[[20]], max(numgrps[17:19]))
## }
##
## eval_maxp <- function(detection_obj) {
##   maxp <- sapply(detection_obj, function(dat) {
##     dat[, sizerp := .N, by = hit_grp]
##     dat[, p := ifelse(sizerp > 1, fin_parent_p, max_p)]
##     max(dat[, .(min_max_p = min(p)), by = hit_grp]$min_max_p)
##   })
##   ## Adding tolerance of .01 here but could be more depending on whether we do any simulation
##   ## FWER should be smaller than at least one of the alpha adjusters
##   expect_lte(maxp[[4]], max(maxp[1:3]) + .01)
##   expect_lte(maxp[[8]], max(maxp[5:7]) + .01)
##   expect_lte(maxp[[12]], max(maxp[9:11]) + .01)
##   expect_lte(maxp[[16]], max(maxp[13:15]) + .01)
##   expect_lte(maxp[[20]], max(maxp[17:19]) + .01)
## }
##
## eval_single_blocks_found <- function(detection_obj) {
##   ## Number of individual blocks detected versus groups (expect more singletons with the alpha adjusting approaches)
##   numsingletons <- sapply(detection_obj, function(dat) {
##     tab <- table(dat$hit_grp)
##     sum(tab == 1)
##   })
##   expect_lte(numsingletons[[4]], min(numsingletons[1:3])) ## FWER should be smaller than at least one of the alpha adjusters
##   expect_lte(numsingletons[[8]], min(numsingletons[5:7]))
##   expect_lte(numsingletons[[12]], min(numsingletons[9:11]))
##   expect_lte(numsingletons[[16]], min(numsingletons[13:15]))
##   expect_lte(numsingletons[[20]], min(numsingletons[17:19]))
## }
##
## eval_treedepth <- function(detection_obj) {
##   treedepth <- sapply(detection_obj, function(dat) {
##     max(stri_count_fixed(dat$node_id, ".")) + 1
##   })
##   expect_lte(treedepth[[4]], max(treedepth[1:3])) ## FWER should be smaller than at least one of the alpha adjusters
##   expect_lte(treedepth[[8]], max(treedepth[5:7]))
##   expect_lte(treedepth[[12]], max(treedepth[9:11]))
##   expect_lte(treedepth[[16]], max(treedepth[13:15]))
##   expect_lte(treedepth[[20]], max(treedepth[17:19]))
## }
##
## eval_minate <- function(detection_obj, atenm) {
##   ## This compares the ATEs detected. I currently think that the fixed alpha approach should not be as sensitive or powerful as the alpha adjusting approaches. But somehow I wrote this test. Leaving it and ignoring it for now. Also the results fail this test. So I think my current intuition is correct.
##   minate <- sapply(detection_obj, function(dat) {
##     min(dat[, min(abs(get(atenm))), by = hit_grp]$V1)
##   })
##   expect_lte(minate[[4]], min(minate[1:3])) ## FWER should be smaller than at least one of the alpha adjusters
##   expect_lte(minate[[8]], min(minate[5:7]))
##   expect_lte(minate[[12]], min(minate[9:11]))
##   expect_lte(minate[[16]], min(minate[13:15]))
##   expect_lte(minate[[20]], min(minate[17:19]))
## }
##

resnms <- apply(alpha_and_splits, 1, function(x) {
  tmp <- paste0(x, collapse = "_", sep = "")
  gsub("NULL", "fwer_fwer", tmp)
})


test_that("alphafns work across splitters for no effects", {
  ## First with no effects at all. So, basically no splitting should happen and no discoveries should be reported.
  tau_null <- mapply(
    FUN = function(afn = afn, sfn = sfn, sby = sby) {
      message(paste(afn, sfn, sby, collapse = ","))
      testing_fn(afn = afn, sfn = sfn, sby = sby, idat = idat3, bdat = bdat4, fmla = Ynull ~ ZF | bF, local_adj = "local_unadj_all_ps")
    },
    afn = alpha_and_splits$afn,
    sfn = alpha_and_splits$sfn,
    sby = alpha_and_splits$splitby, SIMPLIFY = FALSE
  )
  names(tau_null) <- resnms

  tau_null_det <- lapply(seq_along(tau_null), function(i) {
    # message(i)
    fwer <- stri_sub(names(tau_null)[[i]], 1, 4) == "NULL"
    report_detections(tau_null[[i]], fwer = fwer, only_hits = TRUE)
  })
  names(tau_null_det) <- resnms
  ## No approach should detect anything, So we don't imagine any differences between approaches.
  anydetected <- sapply(tau_null_det, nrow)
  expect(all(anydetected == 0), TRUE)
})

## test_that("alphafns work across splitters for large and homogenous effects", {
##  ## All blocks same large effect. Both approaches should detect effects in basically all blocks (blocks only differ in size)
##  tau_homog <- mapply(
##    FUN = function(afn = afn, sfn = sfn, sby = sby) {
##      message(paste(afn, sfn, sby, collapse = ","))
##      testing_fn(afn = afn, sfn = sfn, sby = sby, idat = idat3, bdat = bdat4, fmla = Yhomog ~ ZF | bF, local_adj="local_unadj_all_ps")
##    },
##    afn = alpha_and_splits$afn,
##    sfn = alpha_and_splits$sfn,
##    sby = alpha_and_splits$splitby, SIMPLIFY = FALSE
##  )
##  names(tau_homog) <- resnms
##
##  tau_homog_det <- lapply(seq_along(tau_homog), function(i) {
##    # message(i)
##    fwer <- stri_sub(names(tau_homog)[[i]], 1, 4) == "NULL"
##    report_detections(tau_homog[[i]], fwer = fwer, only_hits = TRUE)
##  })
##  names(tau_homog_det) <- resnms
##  ## We are comparing resnms 1 and 2 and 3 (the two fdr approaches) versus 4 (fwer) etc..
##
##  ## Block 1 is the smallest block but it sometimes triggers a detection
##  table(idat3$bF)
##  block1detected <- sapply(tau_homog_det, function(dat) {
##    any(dat$bF == "1")
##  })
##  table(block1detected)
##  ## So basically all blocks or at least all but the smallest block should be detected
##  numblks_homog <- sapply(tau_homog_det, nrow)
##  expect_equal(all(numblks_homog >= 19), TRUE)
##  ## Each block should be detected  --- they should not be grouped together ---
##  ##  so the number of groups should be 19 as well
##  numgrps_homog <- sapply(tau_homog_det, function(dat) {
##    length(unique(dat$hit_grp))
##  })
##  expect_equal(all(numgrps_homog >= 19), TRUE)
##
##  eval_numgrps(tau_homog_det)
##  ## Number of individual blocks detected versus groups (expect more or same singletons with the alpha adjusting approaches)
##  eval_single_blocks_found(tau_homog_det)
##
##  ## Lowest ate detected (do this by hit_grp) except it should be ok to have some null blocks in groups
##  minate_homog <- sapply(tau_homog_det, function(dat) {
##    min(dat[, min(abs(ate_homog)), by = hit_grp]$V1)
##  })
##
##  ## Highest p detected: Doesn't reliably work in this case with all huge effects.
##  eval_maxp(tau_homog_det)
##
##  # g_homog <- lapply(tau_homog,function(obj){ make_results_ggraph(make_results_tree(obj)) })
##  # for(i in 1:length(g_homog)){
##  #    ggsave(g_homog[[i]], file = paste0("tau_homog_g",i,".pdf"),
##  #           bg = "transparent", width = 14, height = 7)
##  # }
## })
##
##
## test_that("alphafns work across splitters for individually heteogeneous effects and increase with block size. Also some completely null blocks.", {
##  ################################################################################
##  ## Some blocks have no effect at all in norm_inc
##  tau_norm_inc <- mapply(
##    FUN = function(afn = afn, sfn = sfn, sby = sby) {
##      message(paste(afn, sfn, sby, collapse = ","))
##      testing_fn(afn = afn, sfn = sfn, sby = sby, idat = idat3, bdat = bdat4, fmla = Ynorm_inc ~ ZF | bF, local_adj="local_unadj_all_ps")
##    },
##    afn = alpha_and_splits$afn,
##    sfn = alpha_and_splits$sfn,
##    sby = alpha_and_splits$splitby, SIMPLIFY = FALSE
##  )
##  names(tau_norm_inc) <- resnms
##  tau_norm_inc_det <- lapply(seq_along(tau_norm_inc), function(i) {
##    # message(i)
##    fwer <- stri_sub(names(tau_norm_inc)[[i]], 1, 4) == "NULL"
##    report_detections(tau_norm_inc[[i]], fwer = fwer, only_hits = TRUE)
##  })
##  names(tau_norm_inc_det) <- resnms
##
##  ## Number of individual blocks detected versus groups
##  ##  (expect more singletons with the alpha adjusting approaches than with fixed alpha)
##  ## eval_single_blocks_found(tau_norm_inc_det)
##
##  ## Number of blocks detected: this is not clear what to expect because of the ability to declare "detect" for *groups* of blocks.
##  ## So, FWER might stop testing  and return many blocks.
##  numblks_norm_inc <- sapply(tau_norm_inc_det, nrow)
##  # expect_lte(numblks_norm_inc[[3]],min(numblks_norm_inc[1:2]))
##  # expect_lte(numblks_norm_inc[[6]],min(numblks_norm_inc[4:5]))
##  # expect_lte(numblks_norm_inc[[9]],min(numblks_norm_inc[7:8]))
##
##  ## Number of groups of blocks detected: expect more or equal from alpha adjusting
##  eval_numgrps(tau_norm_inc_det)
##  ## Depth of testing (maxdepth): Probably a deeper tree or equal.
##  eval_treedepth(tau_norm_inc_det)
##  ## Lowest ate detected (do this by hit_grp) except it should be ok to have some null blocks in groups
##  ## I currently disagree with # eval_minate --- shouldn't the alpha adjusted approaches be more sensitive and detect smaller ates?
##  ## Commenting this out for now. I have expectations about p-values but not about ates per se
##  ## eval_minate(tau_norm_inc_det, atenm = "ate_norm_inc")
##
##  ## Highest p detected
##  eval_maxp(tau_norm_inc_det)
##  ## Null blocks detected (but this could be ok if they were in a group of other blocks having strong effects, so do by hit_grp)
##  tau_norm_inc_det[[1]][, -c("ate_null", "ate_homog", "ate_tau", "ate_tauv2")]
##  tau_norm_inc_det[[4]][, -c("ate_null", "ate_homog", "ate_tau", "ate_tauv2")]
##  symdiff <- function(x, y) {
##    setdiff(union(x, y), intersect(x, y))
##  } # https://www.r-bloggers.com/symmetric-set-differences-in-r/
##  symdiff(tau_norm_inc_det[[1]]$bF, tau_norm_inc_det[[4]]$bF)
##  symdiff(tau_norm_inc_det[[2]]$bF, tau_norm_inc_det[[4]]$bF)
##  setdiff(tau_norm_inc_det[[1]]$bF, tau_norm_inc_det[[4]]$bF)
##  setdiff(tau_norm_inc_det[[2]]$bF, tau_norm_inc_det[[1]]$bF)
##
##  sort(setdiff(bdat4$bF, tau_norm_inc_det[[1]]$bF))
##  sort(setdiff(bdat4$bF, tau_norm_inc_det[[2]]$bF))
##  sort(setdiff(bdat4$bF, tau_norm_inc_det[[3]]$bF))
##  sort(setdiff(bdat4$bF, tau_norm_inc_det[[4]]$bF))
##  # g_norm_inc <- lapply(tau_norm_inc, function(obj) {
##  #   make_results_ggraph(make_results_tree(obj))
##  # })
##  # for (i in 1:length(g_norm_inc)) {
##  #   ggsave(g_norm_inc[[i]],
##  #     file = paste0("tau_norm_inc_g", i, ".pdf"),
##  #     bg = "transparent", width = 14, height = 7
##  #   )
##  # }
## })
##
## TODO this next not working. Maybe intuitions are wrong?
## test_that("alphafns work across splitters for individually heteogeneous effects
##  and decrease with block size. Also some completely null blocks.", {
##  ## Some blocks have no effect at all in norm_dec
##  tau_norm_dec <- mapply(
##    FUN = function(afn = afn, sfn = sfn, sby = sby) {
##      message(paste(afn, sfn, sby, collapse = ","))
##      testing_fn(afn = afn, sfn = sfn, sby = sby, idat = idat3, bdat = bdat4, fmla = Ynorm_dec ~ ZF | bF)
##    },
##    afn = alpha_and_splits$afn,
##    sfn = alpha_and_splits$sfn,
##    sby = alpha_and_splits$splitby, SIMPLIFY = FALSE
##  )
##  names(tau_norm_dec) <- resnms
##  tau_norm_dec_det <- lapply(seq_along(tau_norm_dec), function(i) {
##    # message(i)
##    fwer <- stri_sub(names(tau_norm_dec)[[i]], 1, 4) == "NULL"
##    report_detections(tau_norm_dec[[i]], fwer = fwer, only_hits = TRUE)
##  })
##  names(tau_norm_dec_det) <- resnms
##  somehits <- sapply(tau_norm_dec_det, nrow) != 0
##
##  tau_norm_dec_det_somehits <- tau_norm_dec_det[somehits]
##  ## eval_maxp(tau_norm_dec_det_somehits)
##  ## eval_minate(tau_norm_dec_det, atenm = "ate_norm_dec")
##  ## eval_numgrps(tau_norm_dec_det_somehits)
##  ## eval_single_blocks_found(tau_norm_dec_det_somehits)
##  ## eval_treedepth(tau_norm_dec_det_somehits)
## })

## test_that("alphafns work across splitters for constant effect that cancel out at the high level
##   (half large and positive, half large and negative).", {
##   ################################################################################
##   ### All blocks have large effects, some are negative and some positive. The
##   ### blocks vary in size so perhaps the more sensitive procedures will be more
##   ### likely to pick up effects in the smaller blocks.
##   table(idat3$bF)
##
##   tau_v1 <- mapply(
##     FUN = function(afn = afn, sfn = sfn, sby = sby) {
##       message(paste(afn, sfn, sby, collapse = ","))
##       testing_fn(afn = afn, sfn = sfn, sby = sby, idat = idat3, bdat = bdat4, fmla = Y ~ ZF | bF)
##     },
##     afn = alpha_and_splits$afn,
##     sfn = alpha_and_splits$sfn,
##     sby = alpha_and_splits$splitby, SIMPLIFY = FALSE
##   )
##   names(tau_v1) <- resnms
##
##   tau_v1_det <- lapply(seq_along(tau_v1), function(i) {
##     # message(i)
##     fwer <- stri_sub(names(tau_v1)[[i]], 1, 4) == "NULL"
##     report_detections(tau_v1[[i]], fwer = fwer, only_hits = TRUE)
##   })
##   names(tau_v1_det) <- resnms
##
##   eval_maxp(tau_v1_det)
##   eval_minate(tau_v1_det, atenm = "ate_tau")
##   eval_numgrps(tau_v1_det)
##   eval_single_blocks_found(tau_v1_det)
##   eval_treedepth(tau_v1_det)
## })
##
##
## test_that("alphafns work across splitters for individually heterogeneous effects block-fixed effects and some completely null blocks.", {
##   ################
##   tau_v2 <- mapply(
##     FUN = function(afn = afn, sfn = sfn, sby = sby) {
##       message(paste(afn, sfn, sby, collapse = ","))
##       testing_fn(afn = afn, sfn = sfn, sby = sby, idat = idat3, bdat = bdat4, fmla = Ytauv2 ~ ZF | bF)
##     },
##     afn = alpha_and_splits$afn,
##     sfn = alpha_and_splits$sfn,
##     sby = alpha_and_splits$splitby, SIMPLIFY = FALSE
##   )
##   names(tau_v2) <- resnms
##
##   tau_v2_det <- lapply(seq_along(tau_v2), function(i) {
##     # message(i)
##     fwer <- stri_sub(names(tau_v2)[[i]], 1, 4) == "NULL"
##     report_detections(tau_v2[[i]], fwer = fwer, only_hits = TRUE)
##   })
##   names(tau_v2_det) <- resnms
##
##   ### maxp and single_blocks don't fit the intuition here. Need to investigate. Commenting out for now.
##   ## eval_maxp(tau_v2_det)
##   ## eval_minate(tau_v2_det, atenm = "ate_tauv2")
##   eval_numgrps(tau_v2_det)
##   # eval_single_blocks_found(tau_v2_det)
##   eval_treedepth(tau_v2_det)
## })
